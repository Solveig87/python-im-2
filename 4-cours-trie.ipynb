{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trie <small>(a little tenderness)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous aviez à faire l'exercice suivant : « Vous écrirez un script qui reçoit en argument un fichier csv et un préfixe. Le script renverra tous les mots du fichier qui commencent par ce préfixe. Vous pourrez travailler sur `austronesian_swadesh.csv` ou `Lexique383.tsv` par exemple. »"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà ce qu'on aurait pu faire. En deux temps :\n",
    "  1. Stockage des mots de Lexique.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a 142694 mots en magasin.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "lexique = '/home/clement/l-pro/rsrc/lexique.org/Lexique383.tsv'\n",
    "words_lexique = []\n",
    "with open(lexique) as data:\n",
    "    reader = csv.DictReader(data, delimiter=\"\\t\")\n",
    "    for item in reader:\n",
    "        words_lexique.append(item['ortho'])\n",
    "print(f\"On a {len(words_lexique)} mots en magasin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  2. Fonction de recherche par préfixe\n",
    "  \n",
    "  C'est la fonction de recherche qui va surtout nous intéresser aujourd'hui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_prefix(words, prefix):\n",
    "    \"\"\"\n",
    "    Search all the string beginning with the given prefix in\n",
    "    a list of words\n",
    "    Args:\n",
    "        words: list of words\n",
    "        prefix: string to search\n",
    "    Returns:\n",
    "        list of words\n",
    "    Raises:\n",
    "        KeyError: if prefix not found\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for word in words:\n",
    "        if len(prefix) > len(word):\n",
    "            continue\n",
    "        elif word[:len(prefix)] == prefix:\n",
    "            res.append(word)\n",
    "    if res:\n",
    "        return res\n",
    "    else:\n",
    "        raise KeyError(f\"No word with prefix {prefix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['constable', 'constamment', 'constance', 'constances', 'constant', 'constante', 'constante', 'constantes', 'constantes', 'constants', 'constat', 'constat', 'constata', 'constatai', 'constataient', 'constatais', 'constatait', 'constatant', 'constatation', 'constatations', 'constate', 'constatent', 'constater', 'constatera', 'constaterai', 'constateraient', 'constaterais', 'constaterait', 'constateras', 'constaterez', 'constateriez', 'constatez', 'constatiez', 'constations', 'constatons', 'constats', 'constats', 'constatâmes', 'constatèrent', 'constaté', 'constatée', 'constatées', 'constatés', 'constellaient', 'constellait', 'constellant', 'constellation', 'constellations', 'constelle', 'constellent', 'constellé', 'constellé', 'constellée', 'constellée', 'constellées', 'constellées', 'constellés', 'consterna', 'consternait', 'consternant', 'consternant', 'consternante', 'consternantes', 'consternants', 'consternation', 'consterne', 'consternent', 'consterné', 'consterné', 'consternée', 'consternée', 'consternées', 'consternées', 'consternés', 'consternés', 'constipant', 'constipation', 'constipations', 'constipe', 'constipé', 'constipé', 'constipé', 'constipée', 'constipée', 'constipée', 'constipées', 'constipés', 'constipés', 'constipés', 'constitua', 'constituaient', 'constituais', 'constituait', 'constituant', 'constituant', 'constituant', 'constituante', 'constituante', 'constituantes', 'constituants', 'constituants', 'constitue', 'constituent', 'constituer', 'constituera', 'constituerai', 'constitueraient', 'constituerais', 'constituerait', 'constitueras', 'constitueront', 'constituez', 'constituions', 'constituons', 'constitutif', 'constitutifs', 'constitution', 'constitutionnaliste', 'constitutionnalité', 'constitutionnel', 'constitutionnelle', 'constitutionnellement', 'constitutionnelles', 'constitutionnels', 'constitutions', 'constituât', 'constituèrent', 'constitué', 'constitué', 'constituée', 'constituée', 'constituées', 'constituées', 'constitués', 'constitués', 'constricteur', 'constricteurs', 'constriction', 'constrictive', 'constrictor', 'constrictor', 'constrictors', 'constrictors', 'constructeur', 'constructeur', 'constructeurs', 'constructeurs', 'constructif', 'constructifs', 'construction', 'constructions', 'constructive', 'constructives', 'constructivisme', 'construira', 'construirai', 'construiraient', 'construirais', 'construirait', 'construiras', 'construire', 'construirez', 'construiriez', 'construirons', 'construiront', 'construis', 'construisaient', 'construisais', 'construisait', 'construisant', 'construise', 'construisent', 'construisez', 'construisiez', 'construisions', 'construisirent', 'construisis', 'construisit', 'construisons', 'construisît', 'construit', 'construite', 'construites', 'construits']\n"
     ]
    }
   ],
   "source": [
    "print(search_prefix(words_lexique, \"const\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.2 ms ± 998 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit search_prefix(words_lexique, \"const\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons ce que ça donne si on prend un lexique plus grand, [lefff](http://pauillac.inria.fr/~sagot/#lefff) par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a 1197641 mots en magasin.\n"
     ]
    }
   ],
   "source": [
    "lexique = '/home/clement/l-pro/rsrc/lefff-3.4.elex/lefff-3.4.elex'\n",
    "words_lefff = []\n",
    "with open(lexique, encoding=\"iso-8859-1\") as data:\n",
    "    reader = csv.reader(data, delimiter=\"\\t\")\n",
    "    for item in reader:\n",
    "        words_lefff.append(item[0])\n",
    "print(f\"On a {len(words_lefff)} mots en magasin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308 ms ± 11.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit search_prefix(words_lefff, \"conv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27.9 ms pour 142 694 mots, 203 ms pour 1 197 641 mots. Ce qui paraît assez logique, la fonction fait autant de tours de boucles qu'il y a de mots dans la liste. Le temps de traitement est directement proportionnel à la taille des données.\n",
    "\n",
    "Cela nous permet de déterminer [la complexité en temps](https://fr.wikipedia.org/wiki/Complexit%C3%A9_en_temps) de notre algorithme. C'est une notion particulièrement importante en informatique, on note la complexité avec le « grand O » $O$. On parle de temps mais c'est le nombre d'étapes de calcul plus que le temps de calcul que l'on détermine avec la complexité.  \n",
    "Ici notre algo a une complexité linéaire $O$ (où n est la taille des données).\n",
    "\n",
    "La recherche de mots à partir de préfixe, nous l'utilisons quotidiennement avec la complétion automatique sur les claviers de téléphone ou les suggestions de requête sur les moteurs de recherche. Deux opérations a priori anodines mais où le temps de traitement est crucial pour l'expérience utilisateur. Un algo avec une complexité $O(n)$ n'est clairement pas adapté.\n",
    "\n",
    "Il existe une structure de données quasi dédiée à ce type d'opérations : le [Trie](https://fr.wikipedia.org/wiki/Trie_(informatique)) ou arbre préfixe ou encore arbre lexicographique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trie <small>(again)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un *trie* est un arbre de la famille des arbres de recherche (*search tree*). L'arbre stocke un ensemble de mots, un caractère par arc. Tous les descendants d'un nœud ont le même préfixe. Chaque mot du dictionnaire correspond à un chemin de la racine vers un nœud de l'arbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://brilliant-staff-media.s3-us-west-2.amazonaws.com/tiffany-wang/tb4AvuIQIg.png\" width=\"400\" height=\"800\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='https://brilliant-staff-media.s3-us-west-2.amazonaws.com/tiffany-wang/tb4AvuIQIg.png', width=400, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe aussi une visualisation très éclairante ici : [https://www.cs.usfca.edu/~galles/visualization/Trie.html](https://www.cs.usfca.edu/~galles/visualization/Trie.html)  \n",
    "Chaque caractère est stocké dans un nœud. C'est à peu près comme ça que nous allons implémenter le *trie*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation en Python\n",
    "\n",
    "Vous connaissez déjà les structures de données de Python. L'idée maintenant est d'implémenter d'autres structures de données à l'aide des « briques » de base : `list`, `set` et `dict` de Python.\n",
    "\n",
    "Nous allons faire une implémentation en objet en définissant ce qu'est un nœud puis un *trie*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Un nœud de trie. Il a un caractère et des nœuds enfants (vide à l'initialisation)\n",
    "    \"\"\"\n",
    "    def __init__(self, char):\n",
    "        self.value = char\n",
    "        self.children = {}\n",
    "        self.end = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trie:\n",
    "    \"\"\"\n",
    "    trie\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        À l'initialisation on a juste un nœud racine vide\n",
    "        \"\"\"\n",
    "        self.root = Node(\"\")\n",
    "        \n",
    "    def insert(self, word):\n",
    "        \"\"\"\n",
    "        Un nouveau mot dans le trie\n",
    "        \"\"\"\n",
    "        node = self.root\n",
    "        \n",
    "        # on parcourt car. par car.\n",
    "        for char in word:\n",
    "            if char in node.children:\n",
    "                node = node.children[char]\n",
    "            else:\n",
    "                # Si un caractère du mot est inconnu\n",
    "                # on ajoute un nouveau nœud\n",
    "                new_node = Node(char)\n",
    "                node.children[char] = new_node\n",
    "                node = new_node\n",
    "        node.end = True\n",
    "        \n",
    "    def _dfs(self, node, prefix):\n",
    "        \"\"\"\n",
    "        parcours du trie en profondeur\n",
    "        \n",
    "        Args:\n",
    "            - node: le nœud de départ\n",
    "            - prefix: le préfixe, point de départ de la recherche\n",
    "        \"\"\"\n",
    "        # cas du nœud terminal\n",
    "        # if not(node.children):\n",
    "        if node.end:\n",
    "            self.output.append(prefix + node.value)\n",
    "        \n",
    "        for child in node.children.values():\n",
    "            self._dfs(child, prefix + node.value)\n",
    "            \n",
    "    def search(self, prefix):\n",
    "        \"\"\"\n",
    "        Cherche tous les mots du trie formés avec le préfixe argument\n",
    "        \"\"\"\n",
    "        self.output = []\n",
    "        node = self.root\n",
    "        \n",
    "        # on se déplace jusqu'au nœud de fin de préfixe\n",
    "        for char in prefix:\n",
    "            if char in node.children:\n",
    "                node = node.children[char]\n",
    "            else:\n",
    "                # pas de préfixe, pas de résultat\n",
    "                return []\n",
    "        \n",
    "        # appel à la fonction récursive\n",
    "        self._dfs(node, prefix[:-1])\n",
    "        return self.output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparons sur les mots de lexique.org et du lefff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_lexique = Trie()\n",
    "for w in words_lexique:\n",
    "    t_lexique.insert(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.4 µs ± 1 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit t_lexique.search('mais')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_lefff = Trie()\n",
    "for w in words_lefff:\n",
    "    t_lefff.insert(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608 µs ± 145 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit t_lefff.search('conv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est beaucoup plus rapide que la méthode basée sur une liste évidemment et surtout la taille du lexique influe peu sur le temps de traitement. Un *trie* a une complexité $O(m)$ où m est la taille du préfixe recherché.  \n",
    "Essayez avec un préfixe court vous verrez que le temps de traitement est plus long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Et si je veux conserver en mémoire le *trie* ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les structures de données de base vous pouvez utiliser JSON, format que vous connaissez. Pour les objets ça n'ira pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json.dump(words_lexique, open('words_lexique.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Trie is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-fab0c7a51b34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_lexique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't_lexique.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/share/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/anaconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/anaconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type Trie is not JSON serializable"
     ]
    }
   ],
   "source": [
    "json.dump(t_lexique, open('t_lexique.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour sérialiser et désérialiser les objets vous pouvez utiliser le module `pickle`  \n",
    "Attention de bien utiliser le mode binaire pour l'ouverture du fichier d'export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(t_lexique, open('t_lexique.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Trie"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_lexique_2 = pickle.load(open('t_lexique.pickle', 'rb'))\n",
    "type(t_lexique_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
